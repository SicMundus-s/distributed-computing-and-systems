# Экспериментальное исследование производительности системы в Kubernetes с использованием Minikube

## Цель эксперимента
Оценить влияние различных конфигураций ресурсов (CPU и RAM) на производительность кластера Kubernetes, развернутого с помощью Minikube, 
а также измерить характеристики времени отклика, использования CPU и RAM при различных уровнях нагрузки

## Настройка и конфигурация кластера
Minikube был настроен с различными конфигурациями ресурсов:
- Конфигурация 1: 2 CPU и 4GB RAM
- Конфигурация 2: 8 CPU и 8GB RAM
- Конфигурация 3: 16 CPU и 16GB RAM (максимальные параметры, поддерживаемые системой)
Для каждой конфигурации кластера проводились тесты нагрузки, чтобы оценить производительность и возможности масштабирования.

## Тестирование и наблюдение:
Проведено мониторинг использования ресурсов (CPU и RAM), а также измерены времена отклика системы на различные уровни нагрузки.
Особое внимание было уделено поведению системы при горизонтальном масштабировании (добавление новых инстансов микросервисов) 
и вертикальном масштабировании (увеличение доступных ресурсов для кластера).

## Результаты и выводы:
-  вертикальное и горизонтальное масштабирование, как показала практика, 3 инстанса основных микросервисов являются оптимальным значением 
при 16 CPU и 16GB RAM, дальше система упирается в основном в вертикальное масштабирование


![250 USERS LOAD.png](data%2Fload%2F250%20USERS%20LOAD.png)
При 250 нагрузка дошла до 900% CPU, 4GB RAM, надо сказать, что тест выполнился в 2 раза быстрее назначенного времени 

![800 USERS LOAD.png](data%2Fload%2F800%20USERS%20LOAD.png)
При 800 нагрузка дошла до 1150% CPU, 5GB RAM

![2000 USERS LOAD.png](data%2Fload%2F2000%20USERS%20LOAD.png)
При 2000 нагрузка дошла до 1300% CPU, 5GB RAM 

![5000 USERS LOAD.png](data%2Fload%2F5000%20USERS%20LOAD.png)
При 5000 почему-то нагрузка снизилась и была равна 1150% CPU и 7GB RAM

Сумарные данные сведены в этих двух таблицах, из них можно сделать вывод, что сервер хоть и держит нагрузку максимально 
примерно в 10000 users, хоть и конкретно этого значения в таблице нет, но запросы от этого не выполняются быстрее 
и сервер начинает дольше выполнять сами тесты, ошибки которые были в последнем тесте не связаны с сервером, они связаны
с использованием Jmeter внутренних библиотек для заполнения табличных данных и рисования графиков.
[aggregate-load.csv](data%2Fload%2Faggregate-load.csv)
[summary-load.csv](data%2Fload%2Fsummary-load.csv)

## Заключение
Эксперимент показал, что для достижения оптимальной производительности в условиях текущей инфраструктуры и задач, 
увеличение числа инстансов микросервисов выше трёх не приводит к заметному улучшению производительности. 
Таким образом, ключевым аспектом является нахождение баланса между вертикальным и горизонтальным масштабированием, 
что позволяет оптимально использовать доступные ресурсы без излишнего перерасхода.


# Экспериментальное исследование доступности системы

## Цель эксперимента
Оценить масштабируемость и доступность системы

## Настройка и конфигурация кластера
Minikube был настроен с различными конфигурациями ресурсов:
- Конфигурация 1: 2 CPU и 4GB RAM
- Конфигурация 2: 8 CPU и 8GB RAM
- Конфигурация 3: 16 CPU и 16GB RAM (максимальные параметры, поддерживаемые системой)
  Для каждой конфигурации кластера проводились тесты нагрузки, чтобы оценить производительность и возможности масштабирования.

При ограниченных ресурсах сервер выдержал соотвественно меньше запросов, максимальное число USERS при 2 CPU = 270
Машстабируемость была достигнута за счёт увеления числа инстансов в нужный момент, доступность за счёт реплицирования БД 
Коэфициент доступности примерно 99%, потери происходят при отключении одного из инстансов приложения, запросы которые 
попали на этот инстанс во время его отключения и в тот момент когда gateway ещё не успела добавить новый инстанс приложения 
к себе в роутинг чтобы распределять запросы на него, таким образом часть запросов теряется

## Результаты и выводы:

### Экспериментальные параметры:
Конфигурация сервера:
В начальной конфигурации сервер был оборудован 2 CPU ядрами.
Нагрузочное тестирование:
Для оценки производительности сервера использовалось нагрузочное тестирование с использованием JMeter.
Было определено, что при наличии 2 CPU сервер выдерживает максимальное число активных пользователей (USERS) равное 270. 
Это число указывает на количество одновременных пользовательских сессий, которое система может обработать,
прежде чем начинает испытывать затруднения с производительностью.

### Обеспечение масштабируемости:
Масштабируемость системы была достигнута за счёт увеличения числа инстансов приложения в ответ на возрастающую нагрузку. 
Это позволило системе поддерживать высокий уровень производительности, несмотря на ограниченные ресурсы.

### Обеспечение доступности:
Репликация баз данных:
Доступность данных обеспечивалась за счёт репликации баз данных. 
Репликация позволяла системе продолжать функционировать даже при потере одного из узлов базы данных, 
тем самым повышая устойчивость системы к отказам.

### Коэффициент доступности:
В течение экспериментов был достигнут коэффициент доступности на уровне примерно 99%. 
Это означает, что система была доступна и функционировала нормально 99% времени.
Потери при отключении инстансов:
Потери данных наблюдались при отключении инстансов приложения. Запросы, поступившие на инстанс в момент его отключения, 
терялись из-за задержек в обновлении маршрутов на уровне шлюза (gateway). 
Это происходило до того, как gateway успевала добавить новый инстанс в свою систему роутинга.

## Заключение 
Исследование показало, что несмотря на ограниченные ресурсы, 
система может быть эффективно масштабирована с помощью управления инстансами приложения и поддерживать 
высокий уровень доступности за счет репликации баз данных